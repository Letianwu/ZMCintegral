{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Coded by ZHANG Junjie (University of Science and Technology of China) in 10/2018.\n",
    "\n",
    "This program is free: you can redistribute it and/or modify it under the terms of \n",
    "the Apache License Version 2.0, January 2004 (http://www.apache.org/licenses/).\n",
    "\n",
    "The program requires python tensorflow and numpy to be pre-installed in your \n",
    "GPU-supported computer. \n",
    "\n",
    "'''\n",
    "ZMCIntegral_VERSION = '2.0'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.eager.context import context, EAGER_MODE, GRAPH_MODE\n",
    "import os,sys\n",
    "import math\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "        \n",
    "# detect if GPU is available on the computer\n",
    "def is_gpu_available(cuda_only = True):\n",
    "    \n",
    "    from tensorflow.python.client import device_lib as _device_lib\n",
    "    \n",
    "    if cuda_only:\n",
    "        gpu_available=[int(x.name[-1]) for x in _device_lib.list_local_devices() if (x.device_type == 'GPU')]\n",
    "        np.save(os.getcwd()+'/multi_temp/gpu_available', gpu_available)\n",
    "    else:\n",
    "        gpu_available=[int(x.name[-1]) for x in _device_lib.list_local_devices() if (x.device_type == 'GPU' or x.device_type == 'SYCL')]\n",
    "        np.save(os.getcwd()+'/multi_temp/gpu_available', gpu_available)\n",
    "        \n",
    "\n",
    "\n",
    "class MCintegral():\n",
    "    \n",
    "    def __init__(self, my_func = None, domain = None, available_GPU = None, num_trials = 5, depth = 2, sigma_multiplication = 4):\n",
    "\n",
    "        '''\n",
    "        Parameters:\n",
    "            my_func: user defined multidimensional function, type:function\n",
    "            domain: integration domain, type:list/numpy_array, eg [[0,1]] or [[0,1],[0,1]]\n",
    "            available_GPU: list of available gpus, type: list, Default: All GPUs detected, eg [0,1,2,3]\n",
    "            num_trial: number of trials, type:int, Default:5\n",
    "            depth: search depth, type:int, Default:2\n",
    "            sigma_multiplication: recalculate the grid if `stddev` larger than `sigma_mean + sigma_multiplication * sigma`, type:float, Default:4\n",
    "        '''\n",
    "        \n",
    "        # choose eager mode\n",
    "        def switch_to(mode):\n",
    "            ctx = context()._eager_context\n",
    "            ctx.mode = mode\n",
    "            ctx.is_eager = (mode == EAGER_MODE)\n",
    "        # set to eager mode\n",
    "        switch_to(EAGER_MODE)\n",
    "        assert tf.executing_eagerly()\n",
    "        \n",
    "        # clean temp file\n",
    "        self.clean_temp()\n",
    "        \n",
    "        # check gpu condition\n",
    "        p = multiprocessing.Process(target = is_gpu_available)\n",
    "        p.daemon = True\n",
    "        p.start()\n",
    "        p.join()\n",
    "        \n",
    "        if available_GPU == None:\n",
    "            available_GPU = np.load(os.getcwd() + '/multi_temp/gpu_available.npy')\n",
    "        \n",
    "        if len(available_GPU) == 0:\n",
    "            raise AssertionError(\"Your computer does not support GPU calculation.\")\n",
    "        \n",
    "        # number of trials\n",
    "        self.num_trials = num_trials\n",
    "            \n",
    "        # depth of the zooming search\n",
    "        self.depth = depth\n",
    "        \n",
    "        # recalculate the grid if `stddev` larger than `sigma_mean + sigma_multiplication * sigma`\n",
    "        self.sigma_multiplication = sigma_multiplication\n",
    "            \n",
    "        # set up initial conditions\n",
    "        self.available_GPU = available_GPU\n",
    "\n",
    "        # initialize the preparing integrated function depend on its domain dimension\n",
    "        self.initial(my_func, domain)\n",
    "        \n",
    "        depth = 0\n",
    "        self.MCresult = self.importance_sampling_iteration(domain, depth)\n",
    "        \n",
    "    def importance_sampling_iteration(self, domain, depth):\n",
    "        depth += 1\n",
    "        MCresult_chunks, large_std_chunk_id, MCresult_std_chunks = self.evaluate(domain)\n",
    "        \n",
    "        if depth < self.depth:\n",
    "            for chunk_id in large_std_chunk_id:\n",
    "                # domain of this chunk\n",
    "                domain_next_level = self.chunk_domian(chunk_id, domain)\n",
    "                # iteration\n",
    "                MCresult_chunks[chunk_id],MCresult_std_chunks[chunk_id] = self.importance_sampling_iteration(domain_next_level, depth)\n",
    "        \n",
    "        # Stop digging if there are no more large stddev chunk\n",
    "        if len(large_std_chunk_id) == 0:\n",
    "            return np.sum(MCresult_chunks,0), np.sum(MCresult_std_chunks,0)\n",
    "\n",
    "        return np.sum(MCresult_chunks,0), np.sum(MCresult_std_chunks,0)\n",
    "    \n",
    "    def evaluate(self, domain):\n",
    "\n",
    "        '''\n",
    "        Monte Carlo integration.\n",
    "        Parameters:\n",
    "            domain: the integration domain, type:list or numpy_array.\n",
    "        '''\n",
    "        \n",
    "        p={}\n",
    "        for i_batch in range(self.n_batches):\n",
    "            def multi_processing():\n",
    "                os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "                os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(i_batch)\n",
    "                result = []\n",
    "                for trial in range(self.num_trials):\n",
    "                    result.append(self.MCkernel(domain, i_batch))\n",
    "                result = np.array(result)\n",
    "                std_result = np.std(result,0)\n",
    "                mean_result = np.mean(result,0)\n",
    "                np.save(os.getcwd()+'/multi_temp/result'+str(i_batch), np.array(mean_result))\n",
    "                np.save(os.getcwd()+'/multi_temp/result_std'+str(i_batch), np.array(std_result))\n",
    "                \n",
    "            # start multi-processing to allocate     \n",
    "            p[i_batch] = multiprocessing.Process(target = multi_processing)\n",
    "            p[i_batch].daemon = True\n",
    "            p[i_batch].start()\n",
    "            \n",
    "        for i_batch in range(self.n_batches):   \n",
    "            p[i_batch].join()\n",
    "                \n",
    "        MCresult = []\n",
    "        MCresult_std = []\n",
    "        for i_batch in range(self.n_batches): \n",
    "            MCresult.append(np.load(os.getcwd()+'/multi_temp/result'+str(i_batch)+'.npy'))\n",
    "            MCresult_std.append(np.load(os.getcwd()+'/multi_temp/result_std'+str(i_batch)+'.npy'))\n",
    "        \n",
    "        MCresult, MCresult_std = np.concatenate(MCresult), np.concatenate(MCresult_std)\n",
    "        \n",
    "        # find out the index of chunks that have very large stddev\n",
    "        if len(np.shape(MCresult))==1:\n",
    "            threshold = np.mean(MCresult_std) + self.sigma_multiplication * np.std(MCresult_std)\n",
    "            large_std_chunk_id = np.where(MCresult_std > threshold)[0]\n",
    "            return MCresult, large_std_chunk_id, MCresult_std\n",
    "        else:\n",
    "            MCresult_std = np.transpose(MCresult_std)\n",
    "            threshold = np.mean(MCresult_std,-1) + self.sigma_multiplication * np.std(MCresult_std,-1)\n",
    "            large_std_chunk_id = np.unique(np.concatenate([np.where(MCresult_std[i] > threshold[i])[0] for i in range(len(MCresult_std))]))\n",
    "            return MCresult, large_std_chunk_id, np.transpose(MCresult_std)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def initial(self, my_func, domain):\n",
    "        '''\n",
    "        To obtain proper initial conditions:\n",
    "            self.dim: number of free variables, type:int,\n",
    "            self.chunk_size: number of samplings in each chunk, type:int\n",
    "            self.n_grid: total number of d-dimensional samplings, type:int\n",
    "            self.n_batches: seperate data into n_batches parts, type:int\n",
    "        Parameters:\n",
    "            my_func: user defined multidimensional function, type:function\n",
    "            domain: integration domain, type:list/numpy_array, eg [[0,1]] or [[0,1],[0,1]]\n",
    "        '''    \n",
    "\n",
    "        # detect if enter a function             \n",
    "        if my_func == None:\n",
    "            raise AssertionError(\"Invalid input function\")\n",
    "        # the preparing integrated function\n",
    "        self.my_func = my_func\n",
    "\n",
    "        # detect if domain is in right form\n",
    "        if domain == None:\n",
    "            raise AssertionError(\"Please enter a domain\")\n",
    "        for temp in domain:\n",
    "            if len(temp) != 2:\n",
    "                raise AssertionError(\"Domain is incorrect\")\n",
    "            if temp[1] < temp[0]:\n",
    "                raise AssertionError(\"Domain [a,b] should satisfy b>a\")\n",
    "        # integrating dimension\n",
    "        self.dim = len(domain)\n",
    "        \n",
    "        # get `total sampling number` and `sampling number in one chunk` depend on dimension of integral       \n",
    "        if self.dim == 1:\n",
    "            self.n_grid = 4194304\n",
    "            self.chunk_size = 65536\n",
    "        elif self.dim == 2:\n",
    "            self.n_grid = (32768)**2\n",
    "            self.chunk_size = (4096)**2\n",
    "        elif self.dim == 3:\n",
    "            self.n_grid = (1024)**3\n",
    "            self.chunk_size = (256)**3\n",
    "        elif self.dim == 4:\n",
    "            self.n_grid = (192)**4\n",
    "            self.chunk_size = (64)**4\n",
    "        elif self.dim == 5:\n",
    "            self.n_grid = (64)**5\n",
    "            self.chunk_size = (32)**5\n",
    "        elif self.dim == 6:\n",
    "            self.n_grid = (32)**6\n",
    "            self.chunk_size = (16)**6\n",
    "        elif self.dim == 7:\n",
    "            self.n_grid = (20)**7\n",
    "            self.chunk_size = (10)**7\n",
    "        elif self.dim == 8:\n",
    "            self.n_grid = (14)**8\n",
    "            self.chunk_size = (7)**8\n",
    "        elif self.dim == 9:\n",
    "            self.n_grid = (10)**9\n",
    "            self.chunk_size = (5)**9\n",
    "        elif self.dim == 10:\n",
    "            self.n_grid = (8)**10\n",
    "            self.chunk_size = (4)**10\n",
    "        elif self.dim == 11:\n",
    "            self.n_grid = (6)**11\n",
    "            self.chunk_size = (3)**11\n",
    "        else:\n",
    "            self.n_grid = (4)**self.dim\n",
    "            self.chunk_size = (2)**self.dim\n",
    "        \n",
    "        '''\n",
    "            below, `int(np.round())` can make sure you got the exact number, \n",
    "            eg: in Python, you may get 7.99999 from 64^(1/2)\n",
    "        '''\n",
    "\n",
    "        # number of samplings in one chunk along one dimension\n",
    "        self.n_grid_x_one_chunk = int(np.round(self.chunk_size**(1/self.dim)))\n",
    "        \n",
    "        # number of chunks\n",
    "        self.n_chunk = int(np.round(self.n_grid/self.chunk_size))\n",
    "        \n",
    "        # number of samplings along one dimension\n",
    "        self.n_grid_x = int(np.round(self.n_grid**(1/self.dim)))\n",
    "        \n",
    "        # number of chunks along one dimension\n",
    "        self.n_chunk_x = int(np.round(self.n_chunk**(1/self.dim)))\n",
    "        \n",
    "        # number of batches\n",
    "        self.n_batches = min([len(self.available_GPU), self.n_chunk])\n",
    "        \n",
    "        # batch_size\n",
    "        self.batch_size = int(np.ceil(self.n_chunk/self.n_batches))\n",
    "\n",
    "    def clean_temp(self):\n",
    "        folder = os.getcwd()+'/multi_temp/'\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            \n",
    "        # clean temp file\n",
    "        for the_file in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, the_file)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "                \n",
    "    def chunk_domian(self, chunk_id, original_domain):\n",
    "\n",
    "        '''\n",
    "        Return:\n",
    "            domain of integration in this chunk.\n",
    "        Parameters:\n",
    "            chunk_id: current chunk id, type:int.\n",
    "            original_domain: the domain of the previous original integration.\n",
    "        '''\n",
    "\n",
    "        chunk_id_d_dim = self.convert_1d_to_nd(chunk_id, self.dim, self.n_chunk_x)\n",
    "        domain_range = np.array([(original_domain[idim][1] - original_domain[idim][0]) / self.n_chunk_x for idim in range(self.dim)], dtype=np.float32)\n",
    "        domain_left = np.array([original_domain[idim][0] + chunk_id_d_dim[idim] * domain_range[idim] for idim in range(self.dim)], dtype=np.float32)\n",
    "        current_domain = [[domain_left[i], domain_left[i] + domain_range[i]] for i in range(self.dim)]\n",
    "        return current_domain\n",
    "    \n",
    "    def convert_1d_to_nd(self, one_d, dim, system_digit):\n",
    "\n",
    "        '''\n",
    "        Function:\n",
    "            convert `one_d` index to `n_d` index of arbitrary systems\n",
    "        Parameters:\n",
    "            one_d: current index in the whole 1 dimension sequence, type:int.\n",
    "            dim: the real system dimension, type:int.\n",
    "            system_digit: the length in one dimension of the real system, type:int.\n",
    "        '''\n",
    "\n",
    "        temp_point = np.zeros(dim)\n",
    "        for i_dim in range(dim):\n",
    "            temp_i_one_d = one_d\n",
    "            for temp_dim in range(dim):\n",
    "                temp_i_one_d -= temp_point[temp_dim] * (system_digit**(dim-temp_dim-1))\n",
    "            temp_point[i_dim] = math.floor(temp_i_one_d / (system_digit**(dim-i_dim-1)))\n",
    "        return temp_point\n",
    "    \n",
    "    def MCkernel(self, domain, i_batch):\n",
    "\n",
    "        '''\n",
    "        Function:\n",
    "            multiprocessing Monte Carlo integration on specific GPU\n",
    "        Parameters:\n",
    "            domain: domain of the integral, eg: [[a,b],[c,d],...].\n",
    "            i_batch: the index of current GPU, type:int.\n",
    "        '''\n",
    "\n",
    "        MCresult = []\n",
    "        for i_chunk in range(self.batch_size):\n",
    "            chunk_id = i_chunk + i_batch * self.batch_size\n",
    "            if chunk_id < self.n_chunk:\n",
    "                chunk_id_d_dim = self.convert_1d_to_nd(chunk_id, self.dim, self.n_chunk_x)\n",
    "             \n",
    "                domain_range = np.array([(domain[idim][1] - domain[idim][0]) / self.n_chunk_x for idim in range(self.dim)], dtype=np.float32)\n",
    "                domain_left = np.array([domain[idim][0] + chunk_id_d_dim[idim] * domain_range[idim] for idim in range(self.dim)], dtype=np.float32)\n",
    "            \n",
    "                # the shape of below two tensors is (self.dim, 1)\n",
    "                dr_tensor = tf.expand_dims(domain_range, 1)\n",
    "                dl_tensor = tf.expand_dims(domain_left, 1)\n",
    "                    \n",
    "                # random variables of sampling points\n",
    "                random_domain_values = tf.add(tf.multiply(tf.random_uniform([self.dim, self.chunk_size], dtype=tf.float32), dr_tensor), dl_tensor)\n",
    "                random_domain_values = list(map(tf.squeeze, tf.split(random_domain_values, self.dim, 0), [0 for i in range(self.dim)]))\n",
    "            \n",
    "                # user defined function, tensor calculation\n",
    "                user_func = self.my_func(random_domain_values)\n",
    "            \n",
    "                # suppress singularities into 0.0\n",
    "                user_func = tf.where(tf.is_nan(user_func), tf.zeros_like(user_func, dtype=tf.float32), user_func)\n",
    "                user_func = tf.where(tf.is_inf(user_func), tf.zeros_like(user_func, dtype=tf.float32), user_func)\n",
    "            \n",
    "                # monte carlo result in this small chunk\n",
    "                MCresult.append(tf.scalar_mul(np.prod(domain_range, dtype=np.float32), tf.reduce_mean(user_func, -1)).numpy())\n",
    "           \n",
    "        return np.array(MCresult) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
